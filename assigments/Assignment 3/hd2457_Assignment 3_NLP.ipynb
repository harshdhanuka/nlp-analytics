{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied Text and Natural Laguage Analytics, Fall 2020\n",
    "\n",
    "#### Assignment 3\n",
    "\n",
    "Submitted by:\n",
    "\n",
    "Harsh Dhanuka, hd2457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize, ngrams, pos_tag, RegexpParser\n",
    "from collections import Counter\n",
    "import urllib.request as url\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Use urllib or requests package to read this CNBC article through its URL link -\n",
    "https://www.cnbc.com/2019/01/17/netflix-price-hike-helps-disney-upcoming-streaming-service-analyst.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.cnbc.com/2019/01/17/netflix-price-hike-helps-disney-upcoming-streaming-service-analyst.html\"\n",
    "html = url.urlopen(link)\n",
    "raw = html.read()\n",
    "#print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use BeautifulSoup or another HTML parsing package to extract text from the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've observed a few problems using this library: \n",
    "- For one, it picked up unwanted text, such as JavaScript source. \n",
    "- Also, it did not interpret HTML entities. For example, I would expect &#39; in HTML source to be converted to an apostrophe in text, just as if I'd pasted the browser content into notepad.\n",
    "\n",
    "I will make some changes to the code, to handle the above mentioned challenges.\n",
    "\n",
    "I will 2 approaches, and verify my results with both, and will pick the one which is ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1\n",
    "This approach is not ideal. I will comment it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup_file = BeautifulSoup(raw, features = \"html.parser\")\n",
    "\n",
    "# Kill all the java script and other style elements from raw:\n",
    "#for script in soup_file([\"script\", \"style\"]):\n",
    "#    script.extract()    # rip it out\n",
    "\n",
    "# Get text content and assign to another variable\n",
    "#text = soup_file.get_text()\n",
    "\n",
    "# Break the text into different lines, to remove all leading and trailing white space on each line\n",
    "#lines = (line.strip() for line in text.splitlines())\n",
    "\n",
    "# Break multi-headlines into a line each\n",
    "#chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "\n",
    "# Drop all blank lines\n",
    "#text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "# Print the forst 2000 text characters\n",
    "#print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2\n",
    "\n",
    "I will use the output from this approach for my analysis.\n",
    "\n",
    "#### Note: \n",
    "I will let the 'head' and 'title' of the article remain in the data. I consider them as important elements in the NLP process, as headers hold a very significant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netflix price hike helps Disney upcoming streaming service: Analyst Skip Navigation SIGN IN Pro Watchlist Make It Select USA INTL Markets Pre-Markets U.S. Markets Currencies Cryptocurrency Futures & Commodities Bonds Funds & ETFs Watchlist Business Economy Finance Health & Science Media Real Estate Energy Transportation Industrials Retail Wealth Life Small Business Investing Invest In You Personal Finance Financial Advisors Trading Nation Options Action ETF Street Buffett Archive Earnings Trader Talk Tech Cybersecurity Enterprise Internet Media Mobile Social Media Venture Capital Tech Guide Politics White House Policy Defense Congress 2020 Elections CNBC TV Live TV Live Audio Latest Video Top Video CEO Interviews Business Day Shows The News with Shepard Smith Entertainment Shows CNBC World Digital Originals Full Episodes Menu SEARCH QUOTES Markets Pre-Markets U.S. Markets Currencies Cryptocurrency Futures & Commodities Bonds Funds & ETFs Watchlist Business Economy Finance Health & Scie\n"
     ]
    }
   ],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', \n",
    "                               #'head', 'title', \n",
    "                               'meta', '[document]'\n",
    "                              ]:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "text = text_from_html(raw)\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use re (regular expression) package to:\n",
    "\n",
    "## a. Find all matches of $ amounts in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 dollar amount values in the article. They are as follows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['325.', '351']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dollar_amounts = re.findall('\\$(.+?) ',text)\n",
    "\n",
    "print(\"There are\", len(dollar_amounts), \"dollar amount values in the article. They are as follows:\")\n",
    "dollar_amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Substitute all numbers with # character and print the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub('[0-9]', '#', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netflix price hike helps Disney upcoming streaming service: Analyst Skip Navigation SIGN IN Pro Watchlist Make It Select USA INTL Markets Pre-Markets U.S. Markets Currencies Cryptocurrency Futures & Commodities Bonds Funds & ETFs Watchlist Business Economy Finance Health & Science Media Real Estate Energy Transportation Industrials Retail Wealth Life Small Business Investing Invest In You Personal Finance Financial Advisors Trading Nation Options Action ETF Street Buffett Archive Earnings Trader Talk Tech Cybersecurity Enterprise Internet Media Mobile Social Media Venture Capital Tech Guide Politics White House Policy Defense Congress #### Elections CNBC TV Live TV Live Audio Latest Video Top Video CEO Interviews Business Day Shows The News with Shepard Smith Entertainment Shows CNBC World Digital Originals Full Episodes Menu SEARCH QUOTES Markets Pre-Markets U.S. Markets Currencies Cryptocurrency Futures & Commodities Bonds Funds & ETFs Watchlist Business Economy Finance Health & Science Media Real Estate Energy Transportation Industrials Retail Wealth Life Small Business Investing Invest In You Personal Finance Financial Advisors Trading Nation Options Action ETF Street Buffett Archive Earnings Trader Talk Tech Cybersecurity Enterprise Internet Media Mobile Social Media Venture Capital Tech Guide Politics White House Policy Defense Congress #### Elections CNBC TV Live TV Live Audio Latest Video Top Video CEO Interviews Business Day Shows The News with Shepard Smith Entertai\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Count (using regular expressions) ”Netflix” and “Disney” mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text = re.split(r'\\W', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Count of the word 'Netflix' is as follows:\n",
      " \n",
      "14\n",
      " \n",
      "Count of the word 'Disney' is as follows:\n",
      " \n",
      "8\n",
      " \n",
      "Count of the word 'Netflix' and Disney' together is as follows:\n",
      " \n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(\" \")\n",
    "print(\"Count of the word 'Netflix' is as follows:\")\n",
    "print(\" \")\n",
    "print(count_text.count('Netflix'))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Count of the word 'Disney' is as follows:\")\n",
    "print(\" \")\n",
    "print(count_text.count('Disney'))\n",
    "\n",
    "print(\" \")\n",
    "print(\"Count of the word 'Netflix' and Disney' together is as follows:\")\n",
    "print(\" \")\n",
    "print(count_text.count('Disney') + count_text.count('Netflix'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Use NTLK and/or Spacy tokenization features to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Tokenize sentences and words\n",
    "\n",
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Netflix price hike helps Disney upcoming streaming service: Analyst Skip Navigation SIGN IN Pro Watchlist Make It Select USA INTL Markets Pre-Markets U.S. Markets Currencies Cryptocurrency Futures & Commodities Bonds Funds & ETFs Watchlist Business Economy Finance Health & Science Media Real Estate Energy Transportation Industrials Retail Wealth Life Small Business Investing Invest In You Personal Finance Financial Advisors Trading Nation Options Action ETF Street Buffett Archive Earnings Trader Talk Tech Cybersecurity Enterprise Internet Media Mobile Social Media Venture Capital Tech Guide Politics White House Policy Defense Congress #### Elections CNBC TV Live TV Live Audio Latest Video Top Video CEO Interviews Business Day Shows The News with Shepard Smith Entertainment Shows CNBC World Digital Originals Full Episodes Menu SEARCH QUOTES Markets Pre-Markets U.S. Markets Currencies Cryptocurrency Futures & Commodities Bonds Funds & ETFs Watchlist Business Economy Finance Health & Science Media Real Estate Energy Transportation Industrials Retail Wealth Life Small Business Investing Invest In You Personal Finance Financial Advisors Trading Nation Options Action ETF Street Buffett Archive Earnings Trader Talk Tech Cybersecurity Enterprise Internet Media Mobile Social Media Venture Capital Tech Guide Politics White House Policy Defense Congress #### Elections CNBC TV Live TV Live Audio Latest Video Top Video CEO Interviews Business Day Shows The News with Shepard Smith Entertainment Shows CNBC World Digital Originals Full Episodes Menu Tech Netflix's price hike is a 'Catch-##'  that actually helps Disney's upcoming streaming service Published Thu, Jan ## #### #:## PM EST Updated Thu, Jan ## #### #:## PM EST Tyler Clifford @_TylerTheTyler_ Key Points Netflix subscription price hike is a \"key dilemma\" that makes future competitors like Disney more viable, New Constructs CEO David Trainer says.\n",
      "\n",
      "However, Aegis Capital's Victory Anthony sees the Netflix price increase as extra money to invest in more original content or pad the bottom line.\n",
      "\n",
      "VIDEO #:## ##:## Netflix's decision to raise prices is a Catch-##, says New Constructs' David Trainer Closing Bell Disney will have a competitive advantage over Netflix when the entertainment conglomerate launches a competing video streaming platform later this year, according to Wall Street analyst David Trainer.\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "for i in range(0,3):\n",
    "    print()\n",
    "    print(sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netflix\n",
      "price\n",
      "hike\n",
      "helps\n",
      "Disney\n",
      "upcoming\n",
      "streaming\n",
      "service\n",
      ":\n",
      "Analyst\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Remove all English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english')[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Netflix', 'price', 'hike', 'helps', 'Disney', 'upcoming', 'streaming', 'service', ':', 'Analyst', 'Skip', 'Navigation', 'SIGN', 'IN', 'Pro', 'Watchlist', 'Make', 'It', 'Select', 'USA', 'INTL', 'Markets', 'Pre-Markets', 'U.S.', 'Markets', 'Currencies', 'Cryptocurrency', 'Futures', '&', 'Commodities', 'Bonds', 'Funds', '&', 'ETFs', 'Watchlist', 'Business', 'Economy', 'Finance', 'Health', '&', 'Science', 'Media', 'Real', 'Estate', 'Energy', 'Transportation', 'Industrials', 'Retail', 'Wealth', 'Life']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "filtered_sentence = [word for word in tokens if not word in stop_words] \n",
    "\n",
    "print(filtered_sentence[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. List and count n-grams for any given input n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(n):\n",
    "    grams = Counter(ngrams(filtered_sentence, n))\n",
    "    items = grams.items()\n",
    "    first_ten = list(items)[:10]\n",
    "    return (\"Count: \",len(grams)), (\"--------------------\"), (\"The first 10 values/pairs are as follows:  \"), first_ten\n",
    "\n",
    "# first_ten is  defined to display only the first 10 items, not display long  output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Count: ', 434),\n",
       " '--------------------',\n",
       " 'The first 10 values/pairs are as follows:  ',\n",
       " [(('Netflix',), 14),\n",
       "  (('price',), 7),\n",
       "  (('hike',), 3),\n",
       "  (('helps',), 2),\n",
       "  (('Disney',), 7),\n",
       "  (('upcoming',), 2),\n",
       "  (('streaming',), 6),\n",
       "  (('service',), 3),\n",
       "  ((':',), 8),\n",
       "  (('Analyst',), 1)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify\n",
    "\n",
    "n_grams(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Count: ', 684),\n",
       " '--------------------',\n",
       " 'The first 10 values/pairs are as follows:  ',\n",
       " [(('Netflix', 'price'), 3),\n",
       "  (('price', 'hike'), 3),\n",
       "  (('hike', 'helps'), 1),\n",
       "  (('helps', 'Disney'), 2),\n",
       "  (('Disney', 'upcoming'), 1),\n",
       "  (('upcoming', 'streaming'), 2),\n",
       "  (('streaming', 'service'), 2),\n",
       "  (('service', ':'), 1),\n",
       "  ((':', 'Analyst'), 1),\n",
       "  (('Analyst', 'Skip'), 1)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify\n",
    "\n",
    "n_grams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Count: ', 758),\n",
       " '--------------------',\n",
       " 'The first 10 values/pairs are as follows:  ',\n",
       " [(('Netflix', 'price', 'hike'), 1),\n",
       "  (('price', 'hike', 'helps'), 1),\n",
       "  (('hike', 'helps', 'Disney'), 1),\n",
       "  (('helps', 'Disney', 'upcoming'), 1),\n",
       "  (('Disney', 'upcoming', 'streaming'), 1),\n",
       "  (('upcoming', 'streaming', 'service'), 2),\n",
       "  (('streaming', 'service', ':'), 1),\n",
       "  (('service', ':', 'Analyst'), 1),\n",
       "  ((':', 'Analyst', 'Skip'), 1),\n",
       "  (('Analyst', 'Skip', 'Navigation'), 1)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify\n",
    "\n",
    "n_grams(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Lemmatize and deduplicate unigrams into a vocabulary of terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Netflix',\n",
       " 'price',\n",
       " 'hike',\n",
       " 'help',\n",
       " 'Disney',\n",
       " 'upcoming',\n",
       " 'streaming',\n",
       " 'service',\n",
       " ':',\n",
       " 'Analyst']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_sentence]\n",
    "lemmatized_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lemmatized_words' is a list of unigrams of lemmatized words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Print bigrams and trigrams in the first 5 sentences\n",
    "\n",
    "####  Initial cleaning, extract first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will first break the article to extract only the first 5 sentences, using the tokenized sentences (as above)\n",
    "\n",
    "five_sentences = sentences[:5]\n",
    "len(five_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Netflix price hike helps Disney upcoming streaming service: Analyst Skip Navigation SIGN IN Pro Watchlist Make It Select USA INTL Markets Pre-Markets U.S. Markets Currencies Cryptocurrency Futures & Commodities Bonds Funds & ETFs Watchlist Business Economy Finance Health & Science Media Real Estate Energy Transportation Industrials Retail Wealth Life Small Business Investing Invest In You Personal Finance Financial Advisors Trading Nation Options Action ETF Street Buffett Archive Earnings Trader Talk Tech Cybersecurity Enterprise Internet Media Mobile Social Media Venture Capital Tech Guide Politics White House Policy Defense Congress #### Elections CNBC TV Live TV Live Audio Latest Video Top Video CEO Interviews Business Day Shows The News with Shepard Smith Entertainment Shows CNBC World Digital Originals Full Episodes Menu SEARCH QUOTES Markets Pre-Markets U.S. Markets Currencies Cryptocurrency Futures & Commodities Bonds Funds & ETFs Watchlist Business Economy Finance Health & Scie'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make it a continuous string\n",
    "\n",
    "five_sentences = (' '.join(word for word in five_sentences))\n",
    "five_sentences[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to word tokens and Remove stopwords\n",
    "\n",
    "tokens_sent = word_tokenize(five_sentences)\n",
    "\n",
    "filtered_five_sent = [word for word in tokens_sent if not word in stop_words]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('Netflix', 'price'), 2),\n",
       " (('price', 'hike'), 3),\n",
       " (('hike', 'helps'), 1),\n",
       " (('helps', 'Disney'), 2),\n",
       " (('Disney', 'upcoming'), 1),\n",
       " (('upcoming', 'streaming'), 2),\n",
       " (('streaming', 'service'), 2),\n",
       " (('service', ':'), 1),\n",
       " ((':', 'Analyst'), 1),\n",
       " (('Analyst', 'Skip'), 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = Counter(ngrams(filtered_five_sent, 2))\n",
    "print(\"Count: \",len(bigrams))\n",
    "list(bigrams.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('Netflix', 'price', 'hike'), 1),\n",
       " (('price', 'hike', 'helps'), 1),\n",
       " (('hike', 'helps', 'Disney'), 1),\n",
       " (('helps', 'Disney', 'upcoming'), 1),\n",
       " (('Disney', 'upcoming', 'streaming'), 1),\n",
       " (('upcoming', 'streaming', 'service'), 2),\n",
       " (('streaming', 'service', ':'), 1),\n",
       " (('service', ':', 'Analyst'), 1),\n",
       " ((':', 'Analyst', 'Skip'), 1),\n",
       " (('Analyst', 'Skip', 'Navigation'), 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = Counter(ngrams(filtered_five_sent, 3))\n",
    "print(\"Count: \",len(trigrams))\n",
    "list(trigrams.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Print POS tags in the first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Netflix', 'NNP'),\n",
       " ('price', 'NN'),\n",
       " ('hike', 'NN'),\n",
       " ('helps', 'VBZ'),\n",
       " ('Disney', 'NNP'),\n",
       " ('upcoming', 'VBG'),\n",
       " ('streaming', 'VBG'),\n",
       " ('service', 'NN'),\n",
       " (':', ':'),\n",
       " ('Analyst', 'NNP')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pos = pos_tag(tokens_sent)\n",
    "sentence_pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('NP', [('Netflix', 'NNP')]),\n",
       " ('price', 'NN'),\n",
       " ('hike', 'NN'),\n",
       " ('helps', 'VBZ'),\n",
       " Tree('NP', [('Disney', 'NNP')]),\n",
       " ('upcoming', 'VBG'),\n",
       " ('streaming', 'VBG'),\n",
       " ('service', 'NN'),\n",
       " (':', ':'),\n",
       " Tree('NP', [('Analyst', 'NNP')])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NNP>}\"\n",
    "cp = RegexpParser(grammar)\n",
    "cp.parse(sentence_pos)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
